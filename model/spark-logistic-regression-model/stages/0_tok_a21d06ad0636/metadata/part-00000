{"class":"org.apache.spark.ml.feature.Tokenizer","timestamp":1701099211658,"sparkVersion":"3.4.1","uid":"tok_a21d06ad0636","paramMap":{"outputCol":"words","inputCol":"text"},"defaultParamMap":{"outputCol":"tok_a21d06ad0636__output"}}
